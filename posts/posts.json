[
  {
    "path": "posts/2020-12-09-2020-12-09-documentclassification-using-regularized-models/",
    "title": "Classifying-abstracts-using-regularized-models",
    "description": "Classifying abstracts using regularized models: covid-19 or sars-2003?",
    "author": [
      {
        "name": "Mihiretu Kebede(PhD)",
        "url": {}
      }
    ],
    "date": "2020-12-11",
    "categories": [],
    "contents": "\r\nIntroduction\r\nClassifying documents to a certain list of categories can provide valuable insights and possibly make the documents more manageable. Document classification is one of the application areas of machine learning. Natural Language Processing(NLP) and machine learning methods can be used to automate classification of documents such as emails(ham/spam categories), articles, books, response to survey questions, sentiments, product reviews(negative/positive), etc.\r\nThere are handful of very good algorithms that can automagically handle text data. In this blog post, I would like to experiment regularized logistic regression machine learning models for classifying abstracts.\r\nI am interested in predicting abstracts that will fall into “SARS_2003” and “COVID_19” categories. For this task, I will use the same data sets that I have used in my previous blog posts. I saved the references files in excel from my previous post. I will simply load this excel file and play with the abstract using qunateda and glmnet packages. 😍\r\nData\r\nI load the data and see a summary of number of characters used to write the abstracts. For this analysis, I will use only abstracts having 200 characters. I will just filter out the abstracts on the lower side of the extreme.\r\nCheck number of covid/sars papers\r\nThe covid abstracts were originally labeled as “included” and sars abstracts as “excluded”. I will simply create a category variable and change the labels to “covid” or “sars”. About 52% of the abstracts have “covid” labels the remaining is “sars”.\r\n\r\n\r\ncovid_sars$category <- covid_sars$Include\r\ncovid_sars$category[covid_sars$category==\"included\"]<-\"covid\"\r\ncovid_sars$category[covid_sars$category==\"not included\"]<-\"sars\"\r\n\r\ntable(covid_sars$category)\r\n\r\n\r\n\r\ncovid  sars \r\n  506   464 \r\n\r\nround(table(covid_sars$category) %>% prop.table()*100, 1)\r\n\r\n\r\n\r\ncovid  sars \r\n 52.2  47.8 \r\n\r\nSplit the data\r\nBefore we do any steps in a text analysis, it is recommended to split the data. Splitting the data after tokenization is not a good approach. So, we will instead split the data into train and test set, tokenize the train and test sets separately, build models, match the variables of the test data set with the train. Finally, we will predict the test data and then evaluate our predictions.\r\n\r\n\r\nlibrary(caret) #For splitting \r\n\r\nset.seed(1234)\r\n\r\ntrainIndex <- createDataPartition(covid_sars$category, p = .8, \r\n                                  list = FALSE, \r\n                                  times = 1)\r\n\r\ntrain <- covid_sars[trainIndex,]\r\ntest  <- covid_sars[-trainIndex,]\r\n\r\ntable(train$category)\r\n\r\n\r\n\r\ncovid  sars \r\n  405   372 \r\n\r\ntable(test$category)\r\n\r\n\r\n\r\ncovid  sars \r\n  101    92 \r\n\r\nnrow(train)\r\n\r\n\r\n[1] 777\r\n\r\nText analysis\r\nIf you are interested in text analysis, I reccommend visiting Quanteda website. Quanteda is a great package for text analysis. One of the great advantage of quanteda is it is super fast, have so many powerful functions. I have tried five different R packages for text data. Based on my personal taste, I would rank them as follows: Quanteda, txt2vec, tidytext, tm.\r\nCreate Corpus\r\n\r\n\r\nrequire(quanteda)\r\n\r\n#Train data\r\ntr <- train[, 6] # the sixth variable is unique label. I will use it as identifier. \r\ntraincorpus <- corpus(train$abstract,\r\n                      docvars = data.frame(trainvars=names(tr)))\r\n#Test data\r\nts <- test[, 6]\r\n\r\ntestcorpus <- corpus(test$abstract,\r\n                     docvars = data.frame(testvars=names(ts)))\r\nsummary(traincorpus,2)\r\n\r\n\r\nCorpus consisting of 777 documents, showing 2 documents:\r\n\r\n  Text Types Tokens Sentences trainvars\r\n text1   165    337        11     label\r\n text2    94    164         5     label\r\n\r\n# Connect the labels with the corpuses\r\ndocid_train <- train$label\r\n\r\ndocnames(traincorpus) <- docid_train\r\nhead(traincorpus,1)\r\n\r\n\r\nCorpus consisting of 1 document and 1 docvar.\r\nAtaguba2020 :\r\n\"The coronavirus disease 2019 (COVID-19) pandemic has affecte...\"\r\n\r\ndocid_test <- test$label\r\ndocnames(testcorpus) <- docid_test\r\n\r\nsummary(testcorpus, 2)\r\n\r\n\r\nCorpus consisting of 193 documents, showing 2 documents:\r\n\r\n         Text Types Tokens Sentences testvars\r\n   Coccia2020   264    782        12    label\r\n Cagliani2020   182    337        16    label\r\n\r\nsummary(traincorpus, 4)\r\n\r\n\r\nCorpus consisting of 777 documents, showing 4 documents:\r\n\r\n        Text Types Tokens Sentences trainvars\r\n Ataguba2020   165    337        11     label\r\n  Sigala2020    94    164         5     label\r\n Lechner2020   103    160         7     label\r\n    Okba2020   118    176         6     label\r\n\r\nTokenize\r\n\r\n\r\ntraintokens <- tokens(traincorpus,\r\n                      remove_punct = TRUE,\r\n                      remove_url = TRUE,\r\n                      remove_numbers = TRUE)\r\n\r\ntraintokens <- tokens_remove(traintokens, \r\n                             pattern=stopwords('en'))\r\n\r\ntesttokens <- tokens(testcorpus,\r\n                     remove_punct = TRUE,\r\n                     remove_url = TRUE,\r\n                     remove_numbers = TRUE)\r\n\r\ntesttokens <- tokens_remove(testtokens, \r\n                             pattern=stopwords('en'))\r\n\r\n\r\n\r\nConstruct the DFM objects\r\n\r\n\r\ndfmat_train <- dfm(traintokens)\r\n\r\ndfmat_test <- dfm(testtokens)\r\n\r\nhead(dfmat_train,2)\r\n\r\n\r\nDocument-feature matrix of: 2 documents, 12,119 features (99.2% sparse) and 1 docvar.\r\n             features\r\ndocs          coronavirus disease covid-19 pandemic affected many\r\n  Ataguba2020           2       2        6        3        1    7\r\n  Sigala2020            0       0        4        1        0    0\r\n             features\r\ndocs          countries increasing morbidity mortality\r\n  Ataguba2020         7          1         2         1\r\n  Sigala2020          0          0         0         0\r\n[ reached max_nfeat ... 12,109 more features ]\r\n\r\nhead(dfmat_test,2)\r\n\r\n\r\nDocument-feature matrix of: 2 documents, 5,484 features (97.0% sparse) and 1 docvar.\r\n              features\r\ndocs           study two goals first explain geo-environmental\r\n  Coccia2020       3   1     1     1       1                 1\r\n  Cagliani2020     0   0     0     0       0                 0\r\n              features\r\ndocs           determinants accelerated diffusion covid-19\r\n  Coccia2020              1           3         3        9\r\n  Cagliani2020            0           0         0        0\r\n[ reached max_nfeat ... 5,474 more features ]\r\n\r\nThe training data has 12,119 features and is 99.2% sparse, while the test data has 5,484 features and 97% sparsity. I will not do anything to reduce the sparsity. But, you may have to do it if you have a large number of observations. Quanteda’s dfm_trim() can do that for you.\r\nTF-IDF weighting is known to improve prediction performance. I will use that here too.\r\n\r\n\r\ndfmat_train_tfidf <- dfm_tfidf(dfmat_train)\r\ndfmat_test_tfidf <- dfm_tfidf(dfmat_test)\r\n\r\n\r\n\r\nLet’s inspect the two tfidf data that were created above.\r\n\r\n\r\nhead(dfmat_train_tfidf, 2)\r\n\r\n\r\nDocument-feature matrix of: 2 documents, 12,119 features (99.2% sparse) and 1 docvar.\r\n             features\r\ndocs          coronavirus   disease covid-19  pandemic affected\r\n  Ataguba2020     0.86811 0.8990239 2.287311 1.8627242 1.182851\r\n  Sigala2020      0       0         1.524874 0.6209081 0       \r\n             features\r\ndocs              many countries increasing morbidity mortality\r\n  Ataguba2020 7.450424  6.911317   1.475448  3.319944  1.126993\r\n  Sigala2020  0         0          0         0         0       \r\n[ reached max_nfeat ... 12,109 more features ]\r\n\r\nhead(dfmat_test_tfidf,2)\r\n\r\n\r\nDocument-feature matrix of: 2 documents, 5,484 features (97.0% sparse) and 1 docvar.\r\n              features\r\ndocs              study      two    goals     first  explain\r\n  Coccia2020   1.659491 0.870584 1.808436 0.7057737 1.984527\r\n  Cagliani2020 0        0        0        0         0       \r\n              features\r\ndocs           geo-environmental determinants accelerated diffusion\r\n  Coccia2020            2.285557     2.285557    5.953582  5.425308\r\n  Cagliani2020          0            0           0         0       \r\n              features\r\ndocs           covid-19\r\n  Coccia2020   3.642693\r\n  Cagliani2020 0       \r\n[ reached max_nfeat ... 5,474 more features ]\r\n\r\nModel building\r\nWhy not logistic regression?\r\nMy data has two class labels(covid vs sars) and all numerical features. Why not logistic regression, then? Well, linear models provide great approaches to predictive modelling given that the assumprions are met! These assumptions (for example: hemoscidascity of variance) are violated when we have more number of features than observations (For example in genetics studies and text analysis, this is often the case). Applying linear models to such data results in biased coefficients, weaker prediction performance scores, overfitting or high out of sample prediction error problems. Hence, penalizing the estimated model coefficients was devised. This method of penalizing linear models is called “Regularization”. There are three most commonly used approaches to regularization for logistic regression: Ridge, LASSO, and Elastic net.\r\nIn Ridge penalty, the estimated model coefficients are penalized by adding the following parameter. SSE \\[\\begin{equation}\r\n\\ SSE = \\sum^n_{i=1} \\left(y_i - \\hat{y}_i\\right)^2 \r\n\\end{equation}\\]\r\n\\[\\begin{equation} \\ SSE + \\lambda \\sum^p_{j=1} \\beta_j^2 \\\r\n\\end{equation}\\]\r\nThis is called L^2 norm. From the above equation if lambda equals 0, the model will be equal to the ordinary least squares model. As approaches to infinity, the penalty will force the model coefficients to be closer to zero but not completely to 0. Ridge penalty is known to systematically handling highly correlated features. In Lasso penalty the model coefficients are penalized by a L1 norm as follows. \\[\\begin{equation}SSE + \\lambda \\sum^p_{j=1} | \\beta_j |\r\n\\end{equation}\\]\r\nLasso penalty unlike ridge pushes all the coefficients all the way to zero. The advantage of Lasso is it improves model performance while also automating feature selection. Only the features that are important will be retianed on the final model.\r\nElastic net combines both Lasso and Ridge penalty parameters. Elastic net takes advantages of both Lasso and Ridge penalty: effective regularization by automated feature selection as well as effectively handling correlated features.\r\nImplementations\r\nProbably the most popular package to implement regualrized models is the glmnet package. This package is lightening fast to tune cross validated models. I watched one very nice webinar tutorial from Dr Trevor Hastie(one of the authors of this package). He mentioned that it is fast because it is programmed in Fortran. I invite you to watch that great webinar here I head I heard there are also other packages like H2O and elastic net. I have never tried any of them.\r\nFor regularized models, we have two main tuning parameters: alpha and lambda. In ridge and Lasso the lambda is the only tuning parameter but alpha is set to be 0 and 1, respectively. For tuning lambda, the cv.glmnet() function provides 100 different data driven lambda values and there is no need to do anything else. Since elastic net combines both Lasso and Ridge penalty, we will have two tuning parameters: alpha and lambda. Alpha can take a number values between between 0 and 1, while lambda can have 100 different data driven lambda values by just using cv.glmnet() function.\r\nAll models require the data to be in a matrix form. The good thing with quanteda is the document feature matrix is already a matrix object we don’t need to change the structure of our data.\r\nRidge\r\n\r\n\r\n# Ridge regression\r\nlibrary(glmnet)\r\nridge_1 <- glmnet(x = dfmat_train, y = train$category, \r\n                    alpha = 0, family = \"binomial\")\r\n#tfidf\r\nridge_1_tfidf <- glmnet(x = dfmat_train_tfidf, y = train$category, \r\n                    alpha = 0, family = \"binomial\")\r\n\r\npar(mfrow = c(1, 2))\r\nplot(ridge_1, xvar=\"lambda\", main=\"Ridge penalty\\n\\n\")\r\nplot(ridge_1_tfidf, xvar=\"lambda\", main=\"Ridge penalty tfidf\\n\\n\")\r\n\r\n\r\n\r\n\r\n\r\n\r\nx <- Sys.time()\r\n\r\nset.seed(123)\r\nridge_min <- cv.glmnet(x=dfmat_train,\r\n                   y=train$category,\r\n                   family=\"binomial\", \r\n                   alpha=0,  # alpha = 0 for ridge regression\r\n                   parallel=TRUE, \r\n                   intercept=TRUE)\r\n\r\n\r\n\r\nAgain using the tf-idf weighted data\r\n\r\n\r\nset.seed(123)\r\nridge_min_tfidf <- cv.glmnet(x=dfmat_train_tfidf,\r\n                   y=train$category,\r\n                   family=\"binomial\", \r\n                   alpha=0,  # alpha = 0 for ridge regression\r\n                   parallel=TRUE, \r\n                   intercept=TRUE)\r\n\r\npar(mfrow = c(1, 2))\r\nplot(ridge_min, main=\"Ridge penalty\\n\\n\")\r\nplot(ridge_min_tfidf, main=\"Ridge penalty_tfidf\\n\\n\")\r\n\r\n\r\n\r\nSys.time() - x\r\n\r\n\r\nTime difference of 30.22081 secs\r\n\r\nLet’s plot the results\r\n\r\n\r\npar(mfrow = c(1, 2))\r\nplot(ridge_1, xvar = \"lambda\", main = \"Ridge penalty\\n\\n\") \r\nabline(v=log(ridge_min$lambda.min), col = \"red\", lty = \"dashed\")\r\nabline(v=log(ridge_min$lambda.1se), col = \"blue\", lty = \"dashed\")\r\n\r\nplot(ridge_1_tfidf, xvar = \"lambda\", main = \"Ridge penalty tfidf\\n\\n\") \r\nabline(v=log(ridge_min_tfidf$lambda.min), col = \"red\", lty = \"dashed\")\r\nabline(v=log(ridge_min_tfidf$lambda.1se), col = \"blue\", lty = \"dashed\")\r\n\r\n\r\n\r\n\r\nPredict the test data sets\r\nBefore we predict the test data, we need to do one very key step. We will predict the test data based on the data that the model was trained. So, features on the test data should match with the features on the training data. Otherwise, the prediction will not work. The model cannot understand anything outside of the features that were in the training data. This is very key step in text prediction. Quanteda provides a nice function for that: dfm_match(). It subsets the features of the test data that were part of the training data.\r\n\r\n\r\ndfmat_matched <- dfm_match(dfmat_test, \r\n                           features = featnames(dfmat_train))\r\n# Match the tfi-idf\r\ndfmat_matched_tfidf <- dfm_match(dfmat_test_tfidf, \r\n                                 features = featnames(dfmat_train_tfidf))\r\n\r\n\r\n\r\nFor prediction, I will use the best model from the cross validated models. The best model lies between the model having the minimum lamda value and the model that has a lambda value within 1 se. Here, I will use the minimum lamda value.\r\n\r\n\r\n# Predict \r\nridge_min\r\n\r\n\r\n\r\nCall:  cv.glmnet(x = dfmat_train, y = train$category, parallel = TRUE,      family = \"binomial\", alpha = 0, intercept = TRUE) \r\n\r\nMeasure: Binomial Deviance \r\n\r\n    Lambda Measure      SE Nonzero\r\nmin  3.060   1.023 0.01754   12119\r\n1se  3.518   1.040 0.01666   12119\r\n\r\nridge_min$lambda.1se\r\n\r\n\r\n[1] 3.518117\r\n\r\nridge_min$lambda.min\r\n\r\n\r\n[1] 3.059879\r\n\r\nactual_class <- as.factor(test$category)\r\npredicted_class.ridge <- predict(ridge_min, newx=dfmat_matched,s=\"lambda.min\", type=\"class\")\r\n\r\ntab_class.ridge <- table(predicted_class.ridge, actual_class)\r\n\r\nconfusionmatrix_ridge <- confusionMatrix(tab_class.ridge, mode=\"everything\", positive=\"covid\")\r\n\r\n\r\n##tfidf\r\nridge_min_tfidf\r\n\r\n\r\n\r\nCall:  cv.glmnet(x = dfmat_train_tfidf, y = train$category, parallel = TRUE,      family = \"binomial\", alpha = 0, intercept = TRUE) \r\n\r\nMeasure: Binomial Deviance \r\n\r\n    Lambda Measure      SE Nonzero\r\nmin  3.060   1.023 0.01754   12119\r\n1se  3.518   1.040 0.01666   12119\r\n\r\nridge_min_tfidf$lambda.1se\r\n\r\n\r\n[1] 3.518117\r\n\r\nridge_min_tfidf$lambda.min\r\n\r\n\r\n[1] 3.059879\r\n\r\nactual_class_tfidf <- as.factor(test$category)\r\npredicted_class.ridge_tfidf <- predict(ridge_min_tfidf, newx=dfmat_matched_tfidf, s=\"lambda.min\", type=\"class\")\r\n\r\ntab_class.ridge_tfidf <- table(predicted_class.ridge_tfidf, actual_class)\r\n\r\nconfusionmatrix_ridge_tfidf <- confusionMatrix(tab_class.ridge_tfidf, mode=\"everything\", positive=\"covid\")\r\n\r\nconfusionmatrix_ridge\r\n\r\n\r\nConfusion Matrix and Statistics\r\n\r\n                     actual_class\r\npredicted_class.ridge covid sars\r\n                covid    85   17\r\n                sars     16   75\r\n                                          \r\n               Accuracy : 0.829           \r\n                 95% CI : (0.7683, 0.8793)\r\n    No Information Rate : 0.5233          \r\n    P-Value [Acc > NIR] : <2e-16          \r\n                                          \r\n                  Kappa : 0.6571          \r\n                                          \r\n Mcnemar's Test P-Value : 1               \r\n                                          \r\n            Sensitivity : 0.8416          \r\n            Specificity : 0.8152          \r\n         Pos Pred Value : 0.8333          \r\n         Neg Pred Value : 0.8242          \r\n              Precision : 0.8333          \r\n                 Recall : 0.8416          \r\n                     F1 : 0.8374          \r\n             Prevalence : 0.5233          \r\n         Detection Rate : 0.4404          \r\n   Detection Prevalence : 0.5285          \r\n      Balanced Accuracy : 0.8284          \r\n                                          \r\n       'Positive' Class : covid           \r\n                                          \r\n\r\nconfusionmatrix_ridge_tfidf\r\n\r\n\r\nConfusion Matrix and Statistics\r\n\r\n                           actual_class\r\npredicted_class.ridge_tfidf covid sars\r\n                      covid    86   17\r\n                      sars     15   75\r\n                                          \r\n               Accuracy : 0.8342          \r\n                 95% CI : (0.7741, 0.8837)\r\n    No Information Rate : 0.5233          \r\n    P-Value [Acc > NIR] : <2e-16          \r\n                                          \r\n                  Kappa : 0.6673          \r\n                                          \r\n Mcnemar's Test P-Value : 0.8597          \r\n                                          \r\n            Sensitivity : 0.8515          \r\n            Specificity : 0.8152          \r\n         Pos Pred Value : 0.8350          \r\n         Neg Pred Value : 0.8333          \r\n              Precision : 0.8350          \r\n                 Recall : 0.8515          \r\n                     F1 : 0.8431          \r\n             Prevalence : 0.5233          \r\n         Detection Rate : 0.4456          \r\n   Detection Prevalence : 0.5337          \r\n      Balanced Accuracy : 0.8334          \r\n                                          \r\n       'Positive' Class : covid           \r\n                                          \r\n\r\nSee, all features are retained in the final models. Looking at the prediction performances of the two, we can see that the tfidf-weighted data has better performance. We will try Lasso if we can improve that.\r\nLasso penalty\r\n\r\n\r\n## Lasso model\r\nlasso_1 <- glmnet(x = dfmat_train, y = train$category, \r\n                    alpha = 1, family = \"binomial\", type.measure=\"class\") \r\n\r\nlasso_1_tfidf <- glmnet(x = dfmat_train, y = train$category, \r\n                    alpha = 1, family = \"binomial\", type.measure=\"class\") \r\n\r\npar(mfrow=c(1,2))\r\n\r\nplot(lasso_1, xvar=\"lambda\", main=\"Lasso penalty\\n\\n\")\r\nplot(lasso_1_tfidf, xvar=\"lambda\", main=\"Lasso penalty tfidf\\n\\n\")\r\n\r\n\r\n\r\n\r\n\r\n\r\nx <- Sys.time()\r\n#registerDoMC(cores=2) # parallelize to speed up\r\nset.seed(123)\r\nlasso <- cv.glmnet(x=dfmat_train,\r\n                   y=train$category,\r\n                   family=\"binomial\", \r\n                   alpha=1,  # alpha = 1: LASSO\r\n                   parallel=TRUE, nfolds = 10,\r\n                   intercept=TRUE) \r\n\r\n# tfidf\r\nset.seed(123)\r\nlasso_tfidf <- cv.glmnet(x=dfmat_train_tfidf,\r\n                   y=train$category,\r\n                   family=\"binomial\", \r\n                   alpha=1,  # alpha = 1: LASSO\r\n                   parallel=TRUE, nfolds = 10,\r\n                   intercept=TRUE)\r\n\r\nSys.time() -x \r\n\r\n\r\nTime difference of 7.336174 secs\r\n\r\nlasso\r\n\r\n\r\n\r\nCall:  cv.glmnet(x = dfmat_train, y = train$category, nfolds = 10, parallel = TRUE,      family = \"binomial\", alpha = 1, intercept = TRUE) \r\n\r\nMeasure: Binomial Deviance \r\n\r\n     Lambda Measure      SE Nonzero\r\nmin 0.02369  0.4939 0.02139      65\r\n1se 0.03132  0.5107 0.01893      16\r\n\r\nlasso_tfidf\r\n\r\n\r\n\r\nCall:  cv.glmnet(x = dfmat_train_tfidf, y = train$category, nfolds = 10,      parallel = TRUE, family = \"binomial\", alpha = 1, intercept = TRUE) \r\n\r\nMeasure: Binomial Deviance \r\n\r\n     Lambda Measure      SE Nonzero\r\nmin 0.02369  0.4939 0.02139      69\r\n1se 0.03132  0.5107 0.01893      16\r\n\r\n\r\n\r\n# Plot lasso without cv and with cv to mark lamda.min and lamda.1se\r\n\r\npar(mfrow=c(1,2))\r\nplot(lasso_1, xvar=\"lambda\", main=\"Lasso penalty \\n\\n\")\r\nabline(v=log(lasso$lambda.min), col=\"red\", lty=\"dashed\")\r\nabline(v=log(lasso$lambda.1se), col=\"blue\", lty=\"dashed\")\r\n\r\nplot(lasso_1_tfidf, xvar=\"lambda\", main=\"Lasso penalty tfidf \\n\\n\")\r\nabline(v=log(lasso_tfidf$lambda.min), col=\"red\", lty=\"dashed\")\r\nabline(v=log(lasso_tfidf$lambda.1se), col=\"blue\", lty=\"dashed\")\r\n\r\n\r\n\r\n\r\n\r\n\r\npar(mfrow=c(1,2))\r\nplot(lasso,main=\"Lasso penalty\\n\\n\")\r\nplot(lasso_tfidf,main=\"Lasso penalty tfidf\\n\\n\")\r\n\r\n\r\n\r\n\r\n\r\n\r\n# Predict \r\nlasso\r\n\r\n\r\n\r\nCall:  cv.glmnet(x = dfmat_train, y = train$category, nfolds = 10, parallel = TRUE,      family = \"binomial\", alpha = 1, intercept = TRUE) \r\n\r\nMeasure: Binomial Deviance \r\n\r\n     Lambda Measure      SE Nonzero\r\nmin 0.02369  0.4939 0.02139      65\r\n1se 0.03132  0.5107 0.01893      16\r\n\r\nlasso_tfidf\r\n\r\n\r\n\r\nCall:  cv.glmnet(x = dfmat_train_tfidf, y = train$category, nfolds = 10,      parallel = TRUE, family = \"binomial\", alpha = 1, intercept = TRUE) \r\n\r\nMeasure: Binomial Deviance \r\n\r\n     Lambda Measure      SE Nonzero\r\nmin 0.02369  0.4939 0.02139      69\r\n1se 0.03132  0.5107 0.01893      16\r\n\r\nlasso$lambda.1se\r\n\r\n\r\n[1] 0.03131881\r\n\r\nlasso$lambda.min\r\n\r\n\r\n[1] 0.02369153\r\n\r\nactual_class <- as.factor(test$category)\r\npredicted_class.lasso <- predict(lasso, newx=dfmat_matched,s=\"lambda.min\", type=\"class\")\r\n\r\ntab_class.lasso <- table(predicted_class.lasso, actual_class)\r\n\r\nconfusion_matrix_lasso <- confusionMatrix(tab_class.lasso, mode=\"everything\", positive=\"covid\")\r\n\r\n\r\n##tfidf\r\nlasso_tfidf$lambda.1se\r\n\r\n\r\n[1] 0.03131881\r\n\r\nlasso_tfidf$lambda.min\r\n\r\n\r\n[1] 0.02369153\r\n\r\nactual_class_tfidf <- as.factor(test$category)\r\npredicted_class.lasso_tfidf <- predict(lasso_tfidf,\r\n                                       newx=dfmat_matched_tfidf,s=\"lambda.min\",\r\n                                       type=\"class\")\r\n\r\ntab_class.lasso_tfidf <- table(predicted_class.lasso_tfidf, actual_class)\r\n\r\nconfusion_matrix_lasso_tfidf <- confusionMatrix(tab_class.lasso_tfidf, mode=\"everything\", positive=\"covid\")\r\n\r\nconfusion_matrix_lasso\r\n\r\n\r\nConfusion Matrix and Statistics\r\n\r\n                     actual_class\r\npredicted_class.lasso covid sars\r\n                covid   100   11\r\n                sars      1   81\r\n                                          \r\n               Accuracy : 0.9378          \r\n                 95% CI : (0.8939, 0.9675)\r\n    No Information Rate : 0.5233          \r\n    P-Value [Acc > NIR] : < 2.2e-16       \r\n                                          \r\n                  Kappa : 0.8748          \r\n                                          \r\n Mcnemar's Test P-Value : 0.009375        \r\n                                          \r\n            Sensitivity : 0.9901          \r\n            Specificity : 0.8804          \r\n         Pos Pred Value : 0.9009          \r\n         Neg Pred Value : 0.9878          \r\n              Precision : 0.9009          \r\n                 Recall : 0.9901          \r\n                     F1 : 0.9434          \r\n             Prevalence : 0.5233          \r\n         Detection Rate : 0.5181          \r\n   Detection Prevalence : 0.5751          \r\n      Balanced Accuracy : 0.9353          \r\n                                          \r\n       'Positive' Class : covid           \r\n                                          \r\n\r\nconfusion_matrix_lasso_tfidf\r\n\r\n\r\nConfusion Matrix and Statistics\r\n\r\n                           actual_class\r\npredicted_class.lasso_tfidf covid sars\r\n                      covid   100   11\r\n                      sars      1   81\r\n                                          \r\n               Accuracy : 0.9378          \r\n                 95% CI : (0.8939, 0.9675)\r\n    No Information Rate : 0.5233          \r\n    P-Value [Acc > NIR] : < 2.2e-16       \r\n                                          \r\n                  Kappa : 0.8748          \r\n                                          \r\n Mcnemar's Test P-Value : 0.009375        \r\n                                          \r\n            Sensitivity : 0.9901          \r\n            Specificity : 0.8804          \r\n         Pos Pred Value : 0.9009          \r\n         Neg Pred Value : 0.9878          \r\n              Precision : 0.9009          \r\n                 Recall : 0.9901          \r\n                     F1 : 0.9434          \r\n             Prevalence : 0.5233          \r\n         Detection Rate : 0.5181          \r\n   Detection Prevalence : 0.5751          \r\n      Balanced Accuracy : 0.9353          \r\n                                          \r\n       'Positive' Class : covid           \r\n                                          \r\n\r\nThe best model in the end retains 65 variables. If we used tf-idf weighting, the best model retains 69 of the 1219 variables. That is great way to reduce the irrelevant features. We can have a look at some of these variables using the vippackage. VIP ranks based on their importance scores.\r\n\r\n\r\nlibrary(vip)\r\nvip(lasso_tfidf, 10)\r\n\r\n\r\n\r\n\r\nLet’s see if this this variables are also the main features in the ridge model.\r\n\r\n\r\nvip(ridge_min_tfidf, 10)\r\n\r\n\r\n\r\n\r\nElastic net\r\nIn my experience with text data, I found elastic net regression having problems with the matrix format of the dfm objects resulted from quanteda. I will have to convert the matrix formats to data frames.\r\n\r\n\r\nda_train <- cbind(category=train$category, \r\n                  convert(dfmat_train, to=\"data.frame\")) \r\n\r\nda_train_tfidf <- cbind(category=train$category, \r\n                        convert(dfmat_train_tfidf, to=\"data.frame\")) \r\n\r\n\r\n\r\n\r\n\r\nncol(dfmat_train)\r\n\r\n\r\n[1] 12119\r\n\r\nncol(da_train)\r\n\r\n\r\n[1] 12121\r\n\r\nda_train <- da_train[,-2] #the document identifier variable should be removed\r\nncol(da_train)\r\n\r\n\r\n[1] 12120\r\n\r\n## The tfidf version \r\nncol(dfmat_train_tfidf)\r\n\r\n\r\n[1] 12119\r\n\r\nncol(da_train_tfidf)\r\n\r\n\r\n[1] 12121\r\n\r\nda_train_tfidf <- da_train_tfidf[,-2] #the document identifier variable should be removed\r\nncol(da_train_tfidf)\r\n\r\n\r\n[1] 12120\r\n\r\n\r\n\r\nda_train_xmatrix <- da_train[,-1]  %>% as.data.frame() %>% as.matrix() \r\nda_train_xdf <- da_train  %>% as.data.frame()\r\n\r\n#for the tf-idf pre-processed data \r\n\r\nda_train_xmatrix_tfidf <- da_train_tfidf[,-1]  %>% as.data.frame() %>% as.matrix() \r\n\r\nda_train_xdf_tfidf <- da_train_tfidf  %>% as.data.frame()\r\n\r\n\r\n\r\n\r\n\r\nda_test_match <- cbind(category=test$category, convert(dfmat_matched, to=\"data.frame\")) \r\n\r\nda_test_match <- da_test_match[,-2] \r\nncol(da_test_match)\r\n\r\n\r\n[1] 12120\r\n\r\nda_test_xmatrix <- da_test_match[,-1]  %>% as.data.frame() %>% as.matrix() \r\nncol(dfmat_matched)\r\n\r\n\r\n[1] 12119\r\n\r\nncol(da_test_xmatrix)\r\n\r\n\r\n[1] 12119\r\n\r\n# Do the same for the tfidf data\r\n\r\nda_test_match_tfidf <- cbind(category=test$category, convert(dfmat_matched_tfidf, to=\"data.frame\")) \r\n\r\nda_test_match_tfidf <- da_test_match_tfidf[,-2] #the document identifier variable should be removed\r\nncol(da_test_match_tfidf)\r\n\r\n\r\n[1] 12120\r\n\r\nda_test_xmatrix_tfidf <- da_test_match_tfidf[,-1]  %>% as.data.frame() %>% as.matrix() # remove the dependent variable\r\n\r\nncol(dfmat_matched_tfidf)\r\n\r\n\r\n[1] 12119\r\n\r\nncol(da_test_xmatrix_tfidf)\r\n\r\n\r\n[1] 12119\r\n\r\n\r\n\r\n# Fit elastic net regression with 10 different alpha values from 0 to 1\r\n\r\nx <- Sys.time()\r\n\r\nset.seed(223)\r\ny=ifelse(da_train_xdf$category==\"covid\", \"1\", \"0\") # convert to numeric labels\r\n                       \r\ncv_glmnet_10_roc <- train(x = da_train_xdf[,-1], \r\n                          y = y, type.measure=\"auc\", method=\"glmnet\",\r\n                          family=\"binomial\", \r\n                          traControl=trainControl(method=\"cv\", number=10),\r\n                          parallel=TRUE,\r\n                          tuneLength=10) # I will use 10 different alpha values between 0 and 1\r\n\r\nx-Sys.time()\r\n\r\n\r\nTime difference of -12.0762 mins\r\n\r\n#tfidf\r\nx <- Sys.time()\r\n\r\nset.seed(223)\r\ncv_glmnet_10_roc_tfidf <- train(x = da_train_xdf_tfidf[,-1], \r\n                                y = y, type.measure=\"auc\", method=\"glmnet\",\r\n                                family=\"binomial\",\r\n                              traControl=trainControl(method=\"cv\",number=10), \r\n                                parallel=TRUE,\r\n                                tuneLength=10) \r\n\r\nx-Sys.time()\r\n\r\n\r\nTime difference of -11.85556 mins\r\n\r\nLet’s visualize the two models\r\n\r\n\r\nlibrary(ggplot2)\r\n\r\nggplot(cv_glmnet_10_roc)\r\n\r\n\r\n\r\n#Tf-idf\r\nggplot(cv_glmnet_10_roc_tfidf)\r\n\r\n\r\n\r\n\r\n\r\n\r\n## Predict using the belastic model cv_glmnet_50\r\npredicted_class.elastic_10 <- predict(cv_glmnet_10_roc, \r\n                                      da_test_xmatrix, \r\n                                      cv_glmnet_10_roc$lamda.min, type=\"raw\")\r\n\r\npredicted_class.elastic_10 <- as.factor(ifelse(predicted_class.elastic_10==0, \r\n                                               \"sars\", \"covid\"))\r\n\r\nconfusion_mat_elastic_net <- confusionMatrix(predicted_class.elastic_10, \r\n                                      actual_class, mode=\"everything\",\r\n                                      positive=\"covid\") \r\n\r\n#Predict the tfidf weighted data\r\n\r\npredicted_class.elastic_10_tfidf <- predict(cv_glmnet_10_roc_tfidf,\r\n                                            da_test_xmatrix_tfidf,\r\n                                            cv_glmnet_10_tfidf$lamda.min, \r\n                                            type=\"raw\")\r\n\r\npredicted_class.elastic_10_tfidf <- as.factor(ifelse(predicted_class.elastic_10_tfidf==0, \"sars\", \"covid\"))\r\nconfusion_mat_elastic_net_tfidf <- confusionMatrix(predicted_class.elastic_10_tfidf, \r\n                                            actual_class, \r\n                                            mode=\"everything\", positive=\"covid\") \r\n\r\nconfusion_mat_elastic_net\r\n\r\n\r\nConfusion Matrix and Statistics\r\n\r\n          Reference\r\nPrediction covid sars\r\n     covid   100   11\r\n     sars      1   81\r\n                                          \r\n               Accuracy : 0.9378          \r\n                 95% CI : (0.8939, 0.9675)\r\n    No Information Rate : 0.5233          \r\n    P-Value [Acc > NIR] : < 2.2e-16       \r\n                                          \r\n                  Kappa : 0.8748          \r\n                                          \r\n Mcnemar's Test P-Value : 0.009375        \r\n                                          \r\n            Sensitivity : 0.9901          \r\n            Specificity : 0.8804          \r\n         Pos Pred Value : 0.9009          \r\n         Neg Pred Value : 0.9878          \r\n              Precision : 0.9009          \r\n                 Recall : 0.9901          \r\n                     F1 : 0.9434          \r\n             Prevalence : 0.5233          \r\n         Detection Rate : 0.5181          \r\n   Detection Prevalence : 0.5751          \r\n      Balanced Accuracy : 0.9353          \r\n                                          \r\n       'Positive' Class : covid           \r\n                                          \r\n\r\nconfusion_mat_elastic_net_tfidf\r\n\r\n\r\nConfusion Matrix and Statistics\r\n\r\n          Reference\r\nPrediction covid sars\r\n     covid   100   11\r\n     sars      1   81\r\n                                          \r\n               Accuracy : 0.9378          \r\n                 95% CI : (0.8939, 0.9675)\r\n    No Information Rate : 0.5233          \r\n    P-Value [Acc > NIR] : < 2.2e-16       \r\n                                          \r\n                  Kappa : 0.8748          \r\n                                          \r\n Mcnemar's Test P-Value : 0.009375        \r\n                                          \r\n            Sensitivity : 0.9901          \r\n            Specificity : 0.8804          \r\n         Pos Pred Value : 0.9009          \r\n         Neg Pred Value : 0.9878          \r\n              Precision : 0.9009          \r\n                 Recall : 0.9901          \r\n                     F1 : 0.9434          \r\n             Prevalence : 0.5233          \r\n         Detection Rate : 0.5181          \r\n   Detection Prevalence : 0.5751          \r\n      Balanced Accuracy : 0.9353          \r\n                                          \r\n       'Positive' Class : covid           \r\n                                          \r\n\r\nFinal remarks\r\nNotice, Lasso and Elastic net models gave us superior prediction performances. A model with a sensitivity of 99%, and a specificity of 88%, and precision of more than 90% is extraordinarily superior to me! Sensitivity and specificity are not affected by prevalence. But, precision(positive predictive value) and negative predictive values are influenced by prevalence.It is possible to calculate confidence intervals for sensitivity and specificity. But, I will not do that here. Since the prevalence of covid abstracts is high(52%), the precission of my predictive models are all high. This may not be the case if your model is dealing with rare cases.\r\nThis book by Bradley Boehmke & Brandon Greenwell is a good reference to learn about machine learning. It is freely available. But, you can also buy a hard copy. It is one of my favorite machine learning books.\r\nContact\r\n@MihiretuKebede1\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2020-12-11T10:30:09+01:00",
    "input_file": "2020-12-09-documentclassification-using-regularized-models.utf8.md"
  },
  {
    "path": "posts/2020-09-30-2020-09-30-plotting-model-coefficients-in-a-forest-plot/",
    "title": "Plotting regression model coefficients in a forest plot",
    "description": "How to plot model coefficients in a forest plot.",
    "author": [
      {
        "name": "Mihiretu Kebede(PhD)",
        "url": {}
      }
    ],
    "date": "2020-10-17",
    "categories": [],
    "preview": "posts/2020-09-30-2020-09-30-plotting-model-coefficients-in-a-forest-plot/meskelflower.jpg",
    "last_modified": "2020-10-17T22:57:16+02:00",
    "input_file": "2020-09-30-plotting-model-coefficients-in-a-forest-plot.utf8.md"
  },
  {
    "path": "posts/2020-08-27-text-machine-learning/",
    "title": "XGboost, Naive Bayes and SVM Machine learning algorithms for facilitating title-abstract screening in systematic reviews: predicting inclusion/exclusion of abstracts",
    "description": "Machine learning methods for document classification.",
    "author": [
      {
        "name": "Mihiretu Kebede(PhD)",
        "url": {}
      }
    ],
    "date": "2020-10-02",
    "categories": [],
    "preview": "posts/2020-08-27-text-machine-learning/previewwordcloud.jpg",
    "last_modified": "2020-10-02T20:52:14+02:00",
    "input_file": "2020-08-27-text-machine-learning.utf8.md"
  },
  {
    "path": "posts/2020-08-10-2020-08-10-text-analysis-of-covid-publications/",
    "title": "Applying text analyses methods on 382 COVID19 journal articles",
    "description": "This blog post is a continuation of my previous blog post on applications of text mining on sampled COVI19 publications.",
    "author": [
      {
        "name": "Mihiretu Kebede(PhD)",
        "url": {}
      }
    ],
    "date": "2020-08-11",
    "categories": [],
    "preview": "posts/2020-08-10-2020-08-10-text-analysis-of-covid-publications/2020-08-10-text-analysis-of-covid-publications_files/figure-html5/unnamed-chunk-14-1.png",
    "last_modified": "2020-08-28T21:31:40+02:00",
    "input_file": {},
    "preview_width": 2600,
    "preview_height": 1600
  },
  {
    "path": "posts/2020-08-04-2020-08-04-abiyahmed/",
    "title": "Digital Reactions Towards Prime Minister Abiy Ahmed's Facebook Activities.",
    "description": "Let's have some fun in visualizing Facebook reactions to prime minister Abiy Ahmed's Facebook posts (June 24 to August 09). This post is an updated version. The previous analysis was only until August 5.",
    "author": [
      {
        "name": "Mihiretu Kebede(PhD)",
        "url": {}
      }
    ],
    "date": "2020-08-06",
    "categories": [],
    "preview": "posts/2020-08-04-2020-08-04-abiyahmed/2020-08-04-abiyahmed_files/figure-html5/unnamed-chunk-5-1.png",
    "last_modified": "2020-08-27T23:07:23+02:00",
    "input_file": {},
    "preview_width": 2600,
    "preview_height": 1600
  },
  {
    "path": "posts/2020-08-03-2020-08-03-covid19/",
    "title": "Applying bibliometric analysis and text mining to COVID-19 publications",
    "description": "Let's have a quick overview of what on COVID-19 related records were added in PubMed on August 03/2020.",
    "author": [
      {
        "name": "Mihiretu Kebede (PhD)",
        "url": {}
      }
    ],
    "date": "2020-08-04",
    "categories": [],
    "preview": "posts/2020-08-03-2020-08-03-covid19/pic.jpg",
    "last_modified": "2020-08-29T20:42:23+02:00",
    "input_file": "2020-08-03-covid19.utf8.md"
  },
  {
    "path": "posts/2020-07-25-2020-07-25-diabetesprevalenceeurope/",
    "title": "Visualizing the prevalence of diabetes in six European countries, 1990-2017",
    "description": "This is a quick demonstration of diabetes prevalence in six European countries. The data are from the the Institute of Health Metrics and Evaluation (IHME).",
    "author": [
      {
        "name": "Mihiretu Kebede(PhD)",
        "url": {}
      }
    ],
    "date": "2020-07-25",
    "categories": [],
    "preview": "posts/2020-07-25-2020-07-25-diabetesprevalenceeurope/2020-07-25-diabetesprevalenceeurope_files/figure-html5/unnamed-chunk-5-1.png",
    "last_modified": "2020-08-27T23:07:23+02:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2020-07-19-animating-scatter-plots/",
    "title": "Animating scatter plots",
    "description": "Creating `Gif` for scatter plots",
    "author": [
      {
        "name": "Mihiretu Kebede(PhD)",
        "url": {}
      }
    ],
    "date": "2020-07-21",
    "categories": [],
    "preview": "posts/2020-07-19-animating-scatter-plots/07-19-2020-animating-scatter-plots_files/figure-html5/setup-1.png",
    "last_modified": "2020-08-27T23:07:23+02:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2020-07-13-Animating-bar-graphs_files/",
    "title": "Animating bar graphs",
    "description": "Here we will have a quick look on how to create `Gif` or animated bar plots",
    "author": [
      {
        "name": "Mihiretu Kebede",
        "url": {}
      }
    ],
    "date": "2020-07-13",
    "categories": [],
    "preview": "posts/2020-07-13-Animating-bar-graphs_files/2020-07-13-Animating-bar-graphs_files/figure-html5/unnamed-chunk-2-1.png",
    "last_modified": "2020-08-27T23:07:23+02:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  }
]
